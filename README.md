# Image-Captioning
a model that takes in an image and provides a corresponding descriptive message. the model was built in a jupyter notebook. the notebook contains contains the code to create the image captioning model from scratch.
the model was created using the COCO dataset. 
COCO is a large image dataset designed for object detection, segmentation, person keypoints detection, stuff segmentation, and caption generation. This package provides Matlab, Python, and Lua APIs that assists in loading, parsing, and visualizing the annotations in COCO. Please visit http://cocodataset.org/ for more information on COCO, including for the data, paper, and tutorials. The exact format of the annotations is also described on the COCO website. The Matlab and Python APIs are complete, the Lua API provides only basic functionality.
the code and link to download the images and associated captions is in the notebook. 
the model was inspired by the show, attend and tell paper : Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A., Salakhudinov, R., Zemel, R. &amp; Bengio, Y.. (2015). Show, Attend and Tell: Neural Image Caption Generation with Visual Attention. <i>Proceedings of the 32nd International Conference on Machine Learning</i>, in <i>Proceedings of Machine Learning Research</i> 37:2048-2057 Available from https://proceedings.mlr.press/v37/xuc15.html.

a django app was built to facilate the running and viewing of the project. a simple runserver comand can easily start the program in a django server

